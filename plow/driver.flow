import plow/pexp/parse;
import plow/dexp/desugar;
import plow/types/typeinference;
import plow/bexp/btype2ttype;
import plow/bexp/pretty;
import plow/lookup;

import plow/tracing;

import fast/fast_path;
import string_utils;

export {
	// Constructs a compilation cache
	makePlowCache(
		// How to report an error
		onError : (string) -> void,
		// The includes we should use to find files
		includes : [string]
	) -> PlowCache;

	// Parse, desugar and type a file, and all the transitive imports
	compilePlow(cache : PlowCache, file : string) -> BModule;
}

PlowCache(
	// How to report an error
	onError : (string) -> void,
	// The includes we should use to find files
	includes : [string], 
	// Map of the Modules we have already parsed and desugared
	modules : BModules,
	// Helpers to look up things in imports
	structLookup : BLookupFromImport<DStruct>,
	unionLookup : BLookupFromImport<DUnion>,
	fieldLookup : BLookupFromImport<[string]>,
	unionFieldLookup : BLookupFromImport<[string]>,
	superTypeLookup : BLookupFromImport<[string]>,
	subTypeLookup : BLookupFromImport<[string]>,
	globalLookup : BLookupFromImport<BGlobal>,
	nativeLookup : BLookupFromImport<BNative>,
	// What is the next id
	nextId : ref int,
	// Awaiting modules that are being parsed
	awaiting : ref Set<string>,
	// Tracing helper
	tracing : Tracing,
	// How many errors have we reported?
	errorCount : ref int,
);

makePlowCache(
	// How to report an error
	onError1 : (string) -> void,
	// The includes we should use to find files
	includes : [string]
) -> PlowCache {
	errorCount = ref 0;
	onError = \e -> {
		errorCount := ^errorCount + 1;
		onError1(e);
	};
	// A helper to lookup structs.
	structLookup = BLookupFromImport("struct", \module, n -> {
			lookupTree(module.structs, n)
		}, \module, n -> {
			containsSet(module.exported.exportedTypes, n)
			|| containsSet(module.exported.exportedTypeNames, n)
		},
		\spath, struct, error -> {
			makeOnError(spath, onError)(struct.pos, error)
		},
		ref makeTree(), ref makeSet()
	);

	// A helper to lookup unions.
	unionLookup = BLookupFromImport("union", \module, n -> {
			lookupTree(module.unions, n)
		}, 
		\module, n -> {
			containsSet(module.exported.exportedTypes, n)
			|| containsSet(module.exported.exportedTypeNames, n)
		},
		\upath, struct, error -> {
			makeOnError(upath, onError)(struct.pos, error)
		},
		ref makeTree(), ref makeSet()
	);

	globalLookup = BLookupFromImport("global", \module, n -> {
			lookupTree(module.globals, n);
		},
		\module, n -> {
			containsSet(module.exported.exportedGlobals, n)
		},
		\upath, gl, error -> {
			makeOnError(upath, onError)(gl.pos, error)
		},
		ref makeTree(), ref makeSet()
	);
	nativeLookup = BLookupFromImport("native", \module, n -> {
			lookupTree(module.natives, n);
		},
		\module, n -> {
			containsSet(module.exported.exportedGlobals, n);
		},
		\upath, nat, error -> {
			makeOnError(upath, onError)(nat.pos, error)
		},
		ref makeTree(), ref makeSet()
	);
	fieldLookup = BLookupFromImport("field", \module, n -> {
			lookupTree(module.fields, n);
		}, \module, n -> {
			structs = getTreeArrayValue(module.fields, n);
			// TODO: Maybe this is too much. We should probably just restrict
			// to those that are exported
			forall(structs, \s -> {
				containsSet(module.exported.exportedTypes, s)
			})
		}, \upath, n, error -> {
			println("TODO: What about the position of this field? " + toString(n));
			makeOnError(upath, onError)(0, error)
		}, ref makeTree(), ref makeSet()
	);
	unionFieldLookup = BLookupFromImport("union-field", \module, n -> {
			unionFields = makeDUnionFields(module.unions, module.structs);
			unions = lookupTreeDef(unionFields, n, makeSet());
			if (isEmptySet(unions)) None()
			else Some(set2array(unions))
		}, \module, n -> {
			// TODO: I guess we could refine this
			true;
		}, \upath, n, error -> {
			println("TODO: What about the position of this field? " + toString(n));
			makeOnError(upath, onError)(0, error)
		}, ref makeTree(), ref makeSet()
	);

	superTypeLookup = BLookupFromImport("supertype", \module, n -> {
			supers = makeDSupers(module.unions);
			Some(getTreeArrayValue(supers, n));
		}, \module, n -> {
			true;
		}, \upath, nat, error -> {
			println("TODO: What about the position of this field? " + toString(nat));
			makeOnError(upath, onError)(0, error)
		}, ref makeTree(), ref makeSet()
	);

	subTypeLookup = BLookupFromImport("subtype", \module, n -> {
			subs = makeDSubtypes(module.unions);
			Some(getTreeArrayValue(subs, n));
		}, \module, n -> {
			true;
		}, \upath, nat, error -> {
			println("TODO: What about the position of this field? " + toString(nat));
			makeOnError(upath, onError)(0, error)
		}, ref makeTree(), ref makeSet()
	);

	PlowCache(
		onError, includes, makeBModules(), 
		structLookup, unionLookup, fieldLookup, 
		unionFieldLookup, superTypeLookup, subTypeLookup,
		globalLookup, nativeLookup,
		ref 0, ref makeSet(), makeTracing(), errorCount
	);
}

clearPlowCache(cache : PlowCache) -> void {
	cache.structLookup.cache := makeTree();
	cache.unionLookup.cache := makeTree();
	cache.fieldLookup.cache := makeTree();
	cache.unionFieldLookup.cache := makeTree();
	cache.superTypeLookup.cache := makeTree();
	cache.subTypeLookup.cache := makeTree();
	cache.globalLookup.cache := makeTree();
	cache.nativeLookup.cache := makeTree();
}

compilePlow(cache : PlowCache, file : string) -> BModule {
	path = fastPath2path(cache.includes, changeFileExt(file, ".flow"));
	flowpath = path2fastPath(cache.includes, path);

	// TODO: We could add a "stop" flag and cancel compilation in those cases
	if (hasCachedBModule(cache.modules, flowpath)) {
		getCachedBModule(cache.modules, flowpath);
	} else if (^(cache.errorCount) != 0) {
		// We stop if there are errors
		println("Stops compilation because of errors: " + flowpath);
		getDummyBModule();
	} else if (hasIncrementalBModule(cache.tracing, cache.modules, path, flowpath)) {
		// OK, we have an incremental module, which we read now
		bmod = getCachedBModule(cache.modules, flowpath);
		// Then make sure we have all dependents as well
		concurrent(false, map(bmod.imports, \i -> {
			\ -> compilePlow(cache, i.path)
		}));
		bmod;
	} else if (containsSet(^(cache.awaiting), flowpath)) {
		getDummyBModule();
	} else if (fileExists(path)) {
		// We should mark this as being processed,
		// so we do not concurrently do the same file many times
		cache.awaiting := insertSet(^(cache.awaiting), flowpath);

		// OK, we have to parse this
		code = getFileContent(path);

		p = parsePExp(code, \e -> cache.onError(path + ":" + e));
		if (isTracingId(cache.tracing, StageParse(), 0, flowpath)) {
			println("Parsed '" + file + "' as " + path);
		}

		// OK, parse all the dependent files
		imports = getDImports(p);
		// TODO: fix this so that concurrent running of imports compilation 
		// wouldn't hang
		sequential(false, map(imports, \i -> {
			\ -> compilePlow(cache, i.path)
		}));

		dd = makeDDesugar(cache.tracing, makeOnError(path, cache.onError), cache.nextId, 
			// resolveStructName
			\n -> {
				// OK, scan our imports for this struct
				lookupFromImport(cache.modules, cache.structLookup, imports, n);
			}, 
			// resolveUnionName
			\n -> {
				// OK, scan our imports for this struct
				lookupFromImport(cache.modules, cache.unionLookup, imports, n)
			}
		);

		dmod = desugarPExp(dd, flowpath, path, p);

		tenv0 = makeTTypeEnv(dd.onError, dmod);
		tenv1 = TTypeEnv(
			tenv0 with
			resolveId = \pos, id -> {
				mbmod : Maybe<BGlobal> = lookupFromImport(cache.modules, cache.globalLookup, imports, id);
				mbmod ?? {
					btype2ttype(mbmod.type);
				} : {
					mbnat : Maybe<BNative> = lookupFromImport(cache.modules, cache.nativeLookup, imports, id);
					switch (mbnat) {
						None(): {
							dd.onError(pos, "Unknown id " + id);
							TTypeEClass(makeTNodeClass(tenv0.tmap));
						}
						Some(bnat): btype2ttype(bnat.type);
					}
				}
			},
			resolveField = \id -> {
				structs : [string] = lookupsFromImport(cache.modules, cache.fieldLookup, imports, id);
				filtermap(structs, \str -> {
					dd.resolveStructName(str);
				})
			},
			resolveUnionField = \id -> {
				buildSet(lookupsFromImport(cache.modules, cache.unionFieldLookup, imports, id));
			},
			resolveSupertypes = \id -> {
				lookupsFromImport(cache.modules, cache.superTypeLookup, imports, id);
			},
			resolveSubtypes = \id -> {
				lookupsFromImport(cache.modules, cache.subTypeLookup, imports, id);
			},
			resolveStructName = dd.resolveStructName,
			resolveUnionName = dd.resolveUnionName
		);
		bmodule = ttypeInference(tenv1, dmod);

		setCachedBModule(cache.modules, flowpath, bmodule);

		if (^(cache.errorCount) != 0) {
			// OK, there are errors, so remove any incremental
			deleteBModule(cache.tracing, flowpath)
		} else {
			writeBModule(cache.tracing, bmodule);
		}

		// OK, clear the name lookup cache
		clearPlowCache(cache);

		if (isTracingId(tenv1.tracing, StageLower(), 1, flowpath)) {
			println(prettyBModule(bmodule));
		}

		bmodule;
	} else {
		cache.onError(file + " could not be found");
		getDummyBModule();
	}
}

makeOnError(file : string, onError : (string) -> void) -> (int, string) -> void {
	resolver = ref None();
	\pos, error -> {
		if (pos == -1 || pos == 0) {
			onError(
				file + ":" + error
			);
		} else {
			res = onlyOnce(resolver, \ -> {
				text = getFileContent(file);
				makeLineResolver(text);
			});
			linecol = findLine(res, pos); // maxi

			indentation = strLeft(linecol.line, linecol.lineIndex - 1);
			spaced = stringFoldChar(indentation, "", \acc, s -> {
				acc + if (s == "\t") s else " ";
			});

			onError(
				file + ":" + i2s(linecol.lineno) + ":" + i2s(linecol.column) + ": " + error
				+ "\n" + linecol.line
				+ "\n" + spaced + "^"
			);
		}
	}
}
